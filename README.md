# ğŸš€ CUDA_Reduced_Memory_Access

A collection of CUDA matrix multiplication kernels optimized to reduce global memory access and maximize GPU throughput. This project demonstrates step-by-step improvements starting from a naive implementation to a fully optimized kernel using shared memory, tiling, and thread coarsening.

---

## ğŸ§  Description

The project evaluates multiple CUDA matrix multiplication approaches (`A * B = C`) for large square matrices in row-major format. Starting with a naive row-wise version, it introduces memory coalescing, 2x2 thread coarsening, shared memory tiling, and finally, a fully optimized 4x4 tiled coarsened kernel. Each version is benchmarked for GFLOPS performance on increasing matrix sizes, with emphasis on reducing memory access and maximizing parallel throughput.

---

## ğŸ”§ Tech Stack

- CUDA
- C++
- cuBLAS (optional comparison)
- Makefile-based build system

---

## âœ¨ Key Features

- âœ… `matmul1_naive`: Basic row-major matrix multiplication kernel  
- âœ… `matmul2_coalesced`: Improved indexing for global memory coalescing  
- âœ… `coarsened_matmul2x2`: Thread coarsening to process 2Ã—2 blocks  
- âœ… `MatMulTiled`: Shared memory tiling with 16Ã—16 thread blocks  
- âœ… `MatmulBest`: Fully optimized 4Ã—4 coarsened, tiled kernel with shared memory  
- âœ… Kernel launcher that selects implementation based on input ID  
- âœ… Configurable with `make` and includes performance output

---

## ğŸ“‚ Folder Structure

```
.
â”œâ”€â”€ Makefile              # Build file
â”œâ”€â”€ matmul                # Executable
â”œâ”€â”€ template.cu           # Source code with all kernels
```

---

## ğŸ› ï¸ Setup & Usage

### âœ… Requirements

- CUDA Toolkit 12.x  
- NVIDIA GPU (Compute Capability 3.5+)  
- Linux/macOS with `make` and `nvcc`

### âš™ï¸ Build

```bash
make
```

### â–¶ï¸ Run

```bash
./matmul
```

Kernels are launched based on an internal ID selector (`kernelId = 1` to `5`). You can modify the selected kernel in the launcher or main file if needed.

---

## ğŸ“ˆ Performance Tips

- Use `kernelId = 5` for the best performance (~10,000 GFLOPS on large matrices)
- Tune `BS` (block size) and `COARSE` (coarsening factor) for further gains
- Avoid kernelId 1 & 2 in production (for benchmarking only)

---

## ğŸ‘¥ Contributors

- Can Ercan (@cann-e)

---
